<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
<!--
       The FreeBSD Documentation Project
       The FreeBSD Brazilian Portuguese Documentation Project

       Original revision: 39566

       $FreeBSD$
- -->
<chapter id="filesystems">
  <chapterinfo>
    <authorgroup>
      <author>
	<firstname>Tom</firstname>
	<surname>Rhodes</surname>
	<contrib>Written by </contrib>
      </author>
    </authorgroup>
  </chapterinfo>

  <title>Suporte a Sistemas de Arquivo</title>

  <sect1 id="filesystems-synopsis">
    <title>Synopsis</title>

    <indexterm><primary>Sistemas de Arquivo</primary></indexterm>
    <indexterm>
      <primary>Suporte a Sistemas de Arquivo</primary>
      <see>Sistemas de Arquivo</see>
    </indexterm>

    <para>O Sistema de Arquivo é parte integral de qualquer sistema
      operacional. Ele permite aos usuários o envio e armazenamento
      de arquivos, provê acesso aos dados e claro, permite o uso do
      disco rigido. É usado em diferentes sistemas operacionais mas
      todos mantêm uma caracteristica comum, que é o sistema de
      arquivo nativo. No &os; o sistema de arquivo é conhecido como
      Fast File System (Sistema de Arquivo Rápido) ou <acronym>FFS
      </acronym> que é baseado no sistema de arquivo original do
      Unix&trade;, também conhecido como <acronym>UFS</acronym>.
      Este é o sistema de arquivo nativo do &os; ao qual é colocado
      nos discos rigidos para acesso a dados.</para>

    <para>&os; também suporta uma variedade de sistemas de arquivo
      para prover suporte a acesso de dados de outros sistemas
      operacionais local, por exemplo,&nbsp;dados armazenados em um
      pendrive <acronym>USB</acronym>, disco flash ou outro disco
      rigido. Existe também suporte a sistemas de arquivos não nativo,
      esses sistemas de arquivo são desenvolvidos em outros sistemas
      operacionais, como o &linux; Extended File System (<acronym>EXT
      </acronym>), e o &sun; Z File System (<acronym>ZFS</acronym>).
      </para>

    <para>Existem diferentes niveis de suporte para vários sistemas de
      arquivo no &os;. Alguns vão requerer a leitura de um modulo do
      kernel e outros vão requerer a instalação de alguma ferramenta.
      Este capitulo é orientado a ajudar os usuários do &os; a 
      acessar outros sistemas de arquivo em seu ambiente, começando
      com o &sun; Z file system (<acronym>ZFS</acronym>).</para>

    <para>Após ler este capítulo, você irá conhecer:</para>

    <itemizedlist>
      <listitem>
	<para>As diferenças entre um sistema de arquivo nativo e um suportado.</para>
      </listitem>

      <listitem>
	<para>Quais sistemas de arquivo são suportados pelo o &os;.</para>
      </listitem>

      <listitem>
	<para>Como habilitar, configurar acessar e gerenciar o uso de
      sistemas de arquivo não nativos.</para>
      </listitem>
    </itemizedlist>

    <para>Antes de ler este capítulo, você precisa:</para>

    <itemizedlist>
      <listitem>
	<para>Conhecer o básico de &unix; e &os;
	  (<xref linkend="basics"/>).</para>
      </listitem>

      <listitem>
	<para>Estar familiarizado com
	  o básico de configuração/compilação de kernel
	  (<xref linkend="kernelconfig"/>).</para>
      </listitem>

      <listitem>
	<para>Estar confortavél em instalar programas de terceiros
	  no &os; (<xref linkend="ports"/>).</para>
      </listitem>

      <listitem>
	<para>Ter alguma familiaridade com discos, storage e nomes de
      dispositivos no &os; (<xref linkend="disks"/>).</para>
      </listitem>
    </itemizedlist>
  </sect1>

  <sect1 id="filesystems-zfs">
    <title>O Z File System (ZFS)</title>

    <para>O Z&nbsp;file system (Sistema de Arquivo Z), desenvolvido
      pela &sun;, é uma nova tecnologia desenvolvida para usar um
      metodo de armazenamento agrupado. Isto significa que o espaço
      somente é usado quando precisa armazenar dados. Ele também é
      desenvolvido para manter a maior integridade possivel do dados,
      suportando o uso de snapshots dos dados, multiplas copias e
      checagem de dados (checksum). Um novo modelo de replicação de
      dados, conhecido como <acronym>RAID</acronym>-Z foi adicionado.
      O modelo <acronym>RAID</acronym>-Z é similar ao <acronym>RAID
      </acronym>5 mas é desenvolvido para prevenir a corrumpção de
      escrita de dados.</para>

    <sect2>
      <title>Ajustes no ZFS</title>

      <para>O subsistema do <acronym>ZFS</acronym> utiliza muito dos
        recursos do sistema, então alguns afinamentos e ajustes são
        requeridos para prover o máximo de eficiencia durante o uso
        diario. Como recurso experimental no &os; algumas coisas podem
        mudar no futuro; entretanto, neste momento, as etapas
        descritas a seguir são recomendadas.</para>

      <sect3>
	<title>Memoria</title>

	<para>O total de memória no sistema deve ser de pelo menos um
      gigabyte, mas o recomendado é que você tenha dois ou mais
      gigabytes. Em todos os exemplos mostrados aqui, o sistema
      possui um gigabyte de memória com outros vários mecanismos
      de ajuste no local.</para>

	<para>Algumas pessoas tiveram sorte de usar menos de um gigabyte
      de memória, porém com uma quantidade limitada de memória
      física, quando o sistema está sob uso pesado, é muito plausivél
      que o &os; terá um panic devido ao uso exaustivel de memória.
    </para>
      </sect3>

      <sect3>
	<title>Configuração de Kernel</title>

	<para>É recomendável remover drivers e opções não usados no
      arquivo de configuração do kernel. Visto que a maioria dos
      dispositivos estão disponíveis como módulos, eles podem ser
      lidos usando o arquivo <filename>/boot/loader.conf</filename>
    </para>

	<para>Usuários da arquitetura &i386; devem adicionar a opção
      descrita abaixo no arquivo de configuração do kernel,
      reconstruir o kernel e reinciar o sistema:</para>

	<programlisting>options 	KVA_PAGES=512</programlisting>

	<para>Esta opção vai expandir o espaço do endereço do kernel,
      permitindo assim que o ajuste <varname>vm.kvm_size</varname>
      possa ser configurado para além do limite atual imposto de
      1&nbsp;GB (2&nbsp;GB para <acronym>PAE</acronym>). Para
      encontrar o valor mais adequado para esta opção, divida o
      espaço de endereço desejado em megabytes por quatro (4). Neste
      caso, é <literal>512</literal> para 2&nbsp;GB.</para>
      </sect3>

      <sect3>
	<title>Carregando os Ajustes</title>

	<para>O espaço de endereço <devicename>kmem</devicename> pode ser
      aumentado em todas as arquiteturas do &os;. No sistema de teste
      com um gigabyte de memória física, para que o sucesso possa ser
      alcançado, deveremos colocar as opções de ajuste no arquivo de
      configuração <filename>/boot/loader.conf</filename> e reiniciar
      o sistema:</para>

	<programlisting>vm.kmem_size="330M"
vm.kmem_size_max="330M"
vfs.zfs.arc_max="40M"
vfs.zfs.vdev.cache.size="5M"</programlisting>

	<para>Para mais detalhes de uma lista de recomendações
      relacionadas aos ajustes do ZFS, veja em (em Inglês)
	  <ulink url="http://wiki.freebsd.org/ZFSTuningGuide"></ulink>.</para>
      </sect3>
    </sect2>

    <sect2>
      <title>Usando <acronym>ZFS</acronym></title>

      <para>Existe um mecanismo de inicialização que permite ao &os;
        montar os conjuntos (pools) do <acronym>ZFS</acronym> durante
	a inicialização do sistema. Para isso, é preciso configura-lo
	através dos seguintes comandos:</para>

	<screen>&prompt.root; <userinput>echo 'zfs_enable="YES"' &gt;&gt; /etc/rc.conf</userinput>
&prompt.root; <userinput>/etc/rc.d/zfs start</userinput></screen>

	<para>Vale lembrar que este documento assume o uso de três
	  discos <acronym>SCSI</acronym>, e que o nome dos
	  dispositivos são <devicename><replaceable>da0</replaceable></devicename>,
	  <devicename><replaceable>da1</replaceable></devicename>
	  e <devicename><replaceable>da2</replaceable></devicename>.
	  Usuários de interface <acronym>IDE</acronym> talvez tenham
	  disponiveis o seguinte nome <devicename><replaceable>ad</replaceable></devicename>
	  ao invés do dispositivo <acronym>SCSI</acronym>.</para>

      <sect3>
	<title>Conjunto (Pool) em Disco Único</title>

	<para>Para criar um simples e não reduntante conjunto (pool)
	  <acronym>ZFS</acronym> usando somente um dispositivo de
	  disco, basta usar o comando <command>zpool</command>:
	  </para>

	<screen>&prompt.root; <userinput>zpool create exemplo /dev/da0</userinput></screen>

	<para>Para ver o novo conjunto (pool), veja a saida do comando
	  <command>df</command>:</para>

	<screen>&prompt.root; <userinput>df</userinput>
Filesystem  1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a   2026030  235230  1628718    13%    /
devfs               1       1        0   100%    /dev
/dev/ad0s1d  54098308 1032846 48737598     2%    /usr
example      17547136       0 17547136     0%    /exemplo</screen>

	<para>Veja que a saída do comando mostra claramente o conjunto
	  <literal>exemplo</literal> e ele não somente criou o
	  conjunto como também já montou ele no sistema. Ele também é
	  acessivel como um sistema de arquivo normal, arquivos podem
	  ser criados e usuários podem navegar como mostrado no
	  exemplo abaixo:</para>

	<screen>&prompt.root; <userinput>cd /exemplo</userinput>
&prompt.root; <userinput>ls</userinput>
&prompt.root; <userinput>touch arquivo_teste</userinput>
&prompt.root; <userinput>ls -al</userinput>
total 4
drwxr-xr-x   2 root  wheel    3 Aug 29 23:15 .
drwxr-xr-x  21 root  wheel  512 Aug 29 23:12 ..
-rw-r--r--   1 root  wheel    0 Aug 29 23:15 arquivo_teste</screen>

	<para>Infelizmente este conjunto (pool) não tem nenhuma
	  vantagem em relação ao uso das funções do <acronym>ZFS</acronym>
	  Crie um sistema de arquivo neste conjunto (pool) e habilite
	  a compressão nele:</para>

	<screen>&prompt.root; <userinput>zfs create exemplo/comprimido</userinput>
&prompt.root; <userinput>zfs set compression=gzip exemplo/comprimido</userinput></screen>

	<para>O <literal>exemplo/comprimido</literal> agora é um
	  sistema de arquivo <acronym>ZFS</acronym> comprimido. Tente
	  copiar algums arquivos grandes para o diretorio 
	  <filename class="directory">/exemplo/comprimido</filename>.</para>

	<para>A compressão pode ser desabilitada agora com o comando:</para>

	<screen>&prompt.root; <userinput>zfs set compression=off exemplo/comprimido</userinput></screen>

	<para>Para desmontar o sistema de arquivo, primeiro execute o
	  comando abaixo e confirme se o mesmo foi desmontado com o
	  comando <command>df</command>:</para>

	<screen>&prompt.root; <userinput>zfs umount exemplo/comprimido</userinput>
&prompt.root; <userinput>df</userinput>
Filesystem  1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a   2026030  235232  1628716    13%    /
devfs               1       1        0   100%    /dev
/dev/ad0s1d  54098308 1032864 48737580     2%    /usr
example      17547008       0 17547008     0%    /exemplo</screen>

	<para>Remonte o sistema de arquivo para permitir o acesso e
	  novamente verifique com o comando <command>df</command>:
	  </para>

	<screen>&prompt.root; <userinput>zfs mount exemplo/comprimido</userinput>
&prompt.root; <userinput>df</userinput>
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a          2026030  235234  1628714    13%    /
devfs                      1       1        0   100%    /dev
/dev/ad0s1d         54098308 1032864 48737580     2%    /usr
example             17547008       0 17547008     0%    /exemplo
example/compressed  17547008       0 17547008     0%    /exemplo/comprimido</screen>

	<para>O conjunto (pool) e o sistema de arquivo podem ser
	  observados na saida do comando <command>mount</command>:
	  </para>

	<screen>&prompt.root; <userinput>mount</userinput>
/dev/ad0s1a on / (ufs, local)
devfs on /dev (devfs, local)
/dev/ad0s1d on /usr (ufs, local, soft-updates)
exemplo on /example (zfs, local)
exemplo/dados on /exemplo/dados (zfs, local)
exemplo/comprimido on /exemplo/comprimido (zfs, local)</screen>

	<para>Como observado, o sistema de arquivo <acronym>ZFS</acronym>
	  após ser criado, já pode ser usado como um sistema de
	  arquivo, entretanto, muitas funções estão disponiveis para
	  configuração. No exemplo mostrado, um novo sistema de
	  arquivo, <literal>dados</literal> foi criado. Arquivos
	  importantes serão armazenados ali, dessa forma, o sistema de
	  arquivo mantém duas cópias de cada bloco de dados:</para>

	<screen>&prompt.root; <userinput>zfs create exemplo/dados</userinput>
&prompt.root; <userinput>zfs set copies=2 exemplo/dados</userinput></screen>

	<para>Vejamos agora o ponto de montagem <literal>dados</literal>
	  e o espaço utilizado por ele, novamente com o comando
	  <command>df</command>:</para>

	<screen>&prompt.root; <userinput>df</userinput>
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a          2026030  235234  1628714    13%    /
devfs                      1       1        0   100%    /dev
/dev/ad0s1d         54098308 1032864 48737580     2%    /usr
exemplo             17547008       0 17547008     0%    /exemplo
exemplo/comprimido  17547008       0 17547008     0%    /exemplo/comprimido
exemplo/dados       17547008       0 17547008     0%    /exemplo/dados</screen>

	<para>Observer que cada sistema de arquivo dentro do conjunto
	  (pool) têm o mesmo espaço disponivel. Notice that each file system on the pool has the same
	  amount of available space.  Essa é a razão de utilizar-mos
	  o comando <command>df</command> em nossos exemplos, para
	  mostrar a quantidade de espaço utilizada apenas pelo o
	  sistema de arquivo, que é uma soma total disponivel no
	  conjunto (pool).
	  O sistema de arquivo <acronym>ZFS</acronym> acaba com
	  alguns conceitos como volumes e partições e permite o uso
	  de vários sistemas de arquivo no mesmo conjunto (pool) file system does away with concepts
	  such as volumes and partitions, and allows for several file
	  systems to occupy the same pool. Vamos destruir o sistema de
	  arquivo e destruir o conjunto (pool) já que não vamos mais
	  precisar dele:</para>

	<screen>&prompt.root; <userinput>zfs destroy exemplo/comprimido</userinput>
&prompt.root; <userinput>zfs destroy exemplo/dados</userinput>
&prompt.root; <userinput>zpool destroy exemplo</userinput></screen>

	<para>Discos podem ser ruins e falharem, ks go bad and fail,
	  é uma caracteristica inevitável. Quando o disco vai mal, os
	  dados podem ser perdidos. Um método para evitar essa perda
	  de dados é a implementação de um <acronym>RAID</acronym>.
	  <acronym>ZFS</acronym> suporta este recurso no ambiente de
	  conjunto (pool) e é o que nós vamos abordar na próxima
	  sessão.</para>
      </sect3>

      <sect3>
	<title><acronym>ZFS</acronym> RAID-Z</title>

	<para>Como observado anteriormente, esta sessão assume a
	  existencia de três discos <acronym>SCSI</acronym> como
	  dispositivos <devicename>da0</devicename>, <devicename>da1</devicename>
	  e <devicename>da2</devicename> (ou <devicename>ad0</devicename>
	  e outros discos IDE no caso de serem usados). Para criar um
	  conjunto (pool) <acronym>RAID</acronym>-Z, execute o
	  seguinte comando:</para>

	<screen>&prompt.root; <userinput>zpool create storage raidz da0 da1 da2</userinput></screen>

	<note><para>A &sun; recomenda que a quantidade de
	  dispositivos utilizados em uma configuração <acronym>RAID</acronym>-Z
	  esteja entre três e nove. Se você necessita usar 10 ou mais
	  discos em um conjunto (pool) simples, pare e pense em usar
	  grupos de <acronym>RAID</acronym>-Z. Se você somente
	  possuir dois discos e necessitar de redundancia, considere
	  usar o espelhamento (mirror) em <acronym>ZFS</acronym>.
	  Veja as páginas de manual (&man.zpool.8;) para maiores
	  detalhes.</para></note>

	<para>O zpool <literal>storage</literal> foi criado com
	  sucesso. Isto pode ser verificado utilizando o comando
	  &man.mount.8; e o comando &man.df.1; conforme visto
	  anteriormente. Mais dispositivos de disco podem ser
	  alocados adicionando-os no final da lista acima. Crie um
	  novo sistema de arquivo neste conjunto (pool), chamado
	  <literal>home</literal>, local onde podem ser colocado
	  arquivos eventuais de usuários:</para>

	<screen>&prompt.root; <userinput>zfs create storage/home</userinput></screen>

	<para>Veja que agora é possivel habilitar a compressão e
	  manter cópias extras dos diretórios e arquivos dos usuários.
	  Isto pode ser configurado, conforme mostramos anteriormente
	  com os comandos descritos abaixo:</para>

	<screen>&prompt.root; <userinput>zfs set copies=2 storage/home</userinput>
&prompt.root; <userinput>zfs set compression=gzip storage/home</userinput></screen>

	<para>Para configurar este ponto de montagem como novo home
	  dos usuários, copie os dados dos usuários para este
	  diretório e crie os links simbolicos necessários:</para>

	<screen>&prompt.root; <userinput>cp -rp /home/* /storage/home</userinput>
&prompt.root; <userinput>rm -rf /home /usr/home</userinput>
&prompt.root; <userinput>ln -s /storage/home /home</userinput>
&prompt.root; <userinput>ln -s /storage/home /usr/home</userinput></screen>

	<para>Os usuários agora podem armazenar dados no sistema de
	  arquivo <filename class="directory">/storage/home</filename>
	  criado recentemente. Faça um teste adicionando um novo
	  usuário no sistema e logue-se como ele.</para>

	<para>Tente criar um instantâneo (snapshot) do sistema de
	  arquivo, para que possa ser recuperado mais tarde:</para>

	<screen>&prompt.root; <userinput>zfs snapshot storage/home@08-30-08</userinput></screen>

	<para>Observe que a opção de snapshot somente capturou o
	  sistema de arquivo real, não um diretório home ou um
	  arquivo. O caracter <literal>@</literal> é um delimitador
	  usado entre o nome do sistema de arquivo e o nome do volume.
	  Quando um home de usuário for enviado para a lixeira,
	  podemos recupera-lo com o comando:</para>

	<screen>&prompt.root; <userinput>zfs rollback storage/home@08-30-08</userinput></screen>

	<para>Para listar todos os snapshots disponiveis, execute
	  <command>ls</command> no diretorio de sistema de arquivo
	  <filename class="directory">.zfs/snapshot</filename>.
	  Por exemplo, para visualizar um possivel snapshot anterior,
	  execute o seguinte comando:</para>

	<screen>&prompt.root; <userinput>ls /storage/home/.zfs/snapshot</userinput></screen>

	<para>É possivel escrever um script para que mensalmente possa
	  criar snapshots dos dados dos usuários, entretanto, a cada
	  vez, os snapshots podem consumir uma quantidade de espaço
	  consideravél do disco. Os snapshots antigos nesse caso,
	  podem ser removidos com o comando descrito abaixo:</para>

	<screen>&prompt.root; <userinput>zfs destroy storage/home@08-30-08</userinput></screen>

	<para>Após todos esses testes, não ha razão para manter-mos
	  o diretório <filename class="directory">/storage/home</filename>
	  neste ponto de montagem. Configure o
	  <filename class="directory">/home</filename> de forma real
	  como um sistema de arquivo:</para>

	<screen>&prompt.root; <userinput>zfs set mountpoint=/home storage/home</userinput></screen>

	<para>Execute o comando <command>df</command> e o comando
	  <command>mount</command> para mostrar como o sistema irá
	  tratar nosso sistema de arquivo como 
	  <filename class="directory">/home</filename>:</para>

	<screen>&prompt.root; <userinput>mount</userinput>
/dev/ad0s1a on / (ufs, local)
devfs on /dev (devfs, local)
/dev/ad0s1d on /usr (ufs, local, soft-updates)
storage on /storage (zfs, local)
storage/home on /home (zfs, local)
&prompt.root; <userinput>df</userinput>
Filesystem   1K-blocks    Used    Avail Capacity  Mounted on
/dev/ad0s1a    2026030  235240  1628708    13%    /
devfs                1       1        0   100%    /dev
/dev/ad0s1d   54098308 1032826 48737618     2%    /usr
storage       26320512       0 26320512     0%    /storage
storage/home  26320512       0 26320512     0%    /home</screen>

	<para>Esta é uma configuração completa do <acronym>RAID</acronym>-Z
	  Para capturar o status e as atualizações do sistema de
	  arquivo criado, pelo o &man.periodic.8; que roda a noite,
	  execute o seguinte comando:</para>

	<screen>&prompt.root; <userinput>echo 'daily_status_zfs_enable="YES"' &gt;&gt; /etc/periodic.conf</userinput></screen>
      </sect3>

      <sect3>
	<title>Recuperando um <acronym>RAID</acronym>-Z</title>

	<para>Every software <acronym>RAID</acronym> has a method of
	  monitoring their <literal>state</literal>.
	  <acronym>ZFS</acronym> is no exception.  The status of
	  <acronym>RAID</acronym>-Z devices may be viewed with the
	  following command:</para>

	<screen>&prompt.root; <userinput>zpool status -x</userinput></screen>

	<para>If all pools are healthy and everything is normal, the
	  following message will be returned:</para>

	<screen>all pools are healthy</screen>

	<para>If there is an issue, perhaps a disk has gone offline,
	  the pool state will be returned and look similar to:</para>

	<screen>  pool: storage
 state: DEGRADED
status: One or more devices has been taken offline by the administrator.
	Sufficient replicas exist for the pool to continue functioning in a
	degraded state.
action: Online the device using 'zpool online' or replace the device with
	'zpool replace'.
 scrub: none requested
config:

	NAME        STATE     READ WRITE CKSUM
	storage     DEGRADED     0     0     0
	  raidz1    DEGRADED     0     0     0
	    da0     ONLINE       0     0     0
	    da1     OFFLINE      0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</screen>

	<para>This states that the device was taken offline by the
	  administrator.  This is true for this particular example.
	  To take the disk offline, the following command was
	  used:</para>

	<screen>&prompt.root; <userinput>zpool offline storage da1</userinput></screen>

	<para>It is now possible to replace the
	  <devicename>da1</devicename> after the system has been
	  powered down.  When the system is back online, the following
	  command may issued to replace the disk:</para>

	<screen>&prompt.root; <userinput>zpool replace storage da1</userinput></screen>

	<para>From here, the status may be checked again, this time
	  without the <option>-x</option> flag to get state
	  information:</para>

	<screen>&prompt.root; <userinput>zpool status storage</userinput>
 pool: storage
 state: ONLINE
 scrub: resilver completed with 0 errors on Sat Aug 30 19:44:11 2008
config:

	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       0     0     0
	  raidz1    ONLINE       0     0     0
	    da0     ONLINE       0     0     0
	    da1     ONLINE       0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</screen>

	<para>As shown from this example, everything appears to be
	  normal.</para>
      </sect3>

      <sect3>
	<title>Data Verification</title>

	<para>As previously mentioned, <acronym>ZFS</acronym> uses
	  <literal>checksums</literal> to verify the integrity of
	  stored data.  They are enabled automatically upon creation
	  of file systems and may be disabled using the following
	  command:</para>

	<screen>&prompt.root; <userinput>zfs set checksum=off storage/home</userinput></screen>

	<para>This is not a wise idea, however, as checksums take
	  very little storage space and are more useful when enabled.  There
	  also appears to be no noticeable costs in having them enabled.
	  While enabled, it is possible to have <acronym>ZFS</acronym>
	  check data integrity using checksum verification.  This
	  process is known as <quote>scrubbing.</quote>  To verify the
	  data integrity of the <literal>storage</literal> pool, issue
	  the following command:</para>

	<screen>&prompt.root; <userinput>zpool scrub storage</userinput></screen>

	<para>This process may take considerable time depending on
	  the amount of data stored.  It is also very
	  <acronym>I/O</acronym> intensive, so much that only one
	  of these operations may be run at any given time.  After
	  the scrub has completed, the status is updated and may be
	  viewed by issuing a status request:</para>

	<screen>&prompt.root; <userinput>zpool status storage</userinput>
 pool: storage
 state: ONLINE
 scrub: scrub completed with 0 errors on Sat Aug 30 19:57:37 2008
config:

	NAME        STATE     READ WRITE CKSUM
	storage     ONLINE       0     0     0
	  raidz1    ONLINE       0     0     0
	    da0     ONLINE       0     0     0
	    da1     ONLINE       0     0     0
	    da2     ONLINE       0     0     0

errors: No known data errors</screen>

	<para>The completion time is in plain view in this example.
	  This feature helps to ensure data integrity over a long
	  period of time.</para>

	<para>There are many more options for the Z&nbsp;file system,
	  see the &man.zfs.8; and &man.zpool.8; manual
	  pages.</para>
      </sect3>

      <sect3>
		<title>ZFS Quotas</title>

		<para>ZFS supports different types of quotas; the refquota, the
		  general quota, the user quota, and the group quota.  This
		  section will explain the basics of each one, and include some
		  usage instructions.</para>

		<para>Quotas limit the amount of space that a dataset and its
		  descendants can consume, and enforce a limit on the amount of
		  space used by filesystems and snapshots for the descendants.
		  In terms of users, quotas are useful to limit the amount of
		  space a particular user can use.</para>

		<note>
	  	  <para>Quotas cannot be set on volumes, as the
	  	    <literal>volsize</literal> property acts as an implicit
	  	    quota.</para>
		</note>

		<para>The refquota,
		  <literal>refquota=<replaceable>size</replaceable></literal>,
		  limits the amount of space a dataset can consume by enforcing
		  a hard limit on the space used.  However, this hard limit does
		  not include space used by descendants, such as file systems or
		  snapshots.</para>

		<para>To enforce a general quota of 10&nbsp;GB for
		  <filename>storage/home/bob</filename>, use the
		  following:</para>

		<screen>&prompt.root; <userinput>zfs set quota=10G storage/home/bob</userinput></screen>

		<para>User quotas limit the amount of space that can be used by
		  the specified user.  The general format is
		  <literal>userquota@<replaceable>user</replaceable>=<replaceable>size</replaceable></literal>,
		  and the user's name must be in one of the following
		  formats:</para>

		<itemizedlist>
	  	  <listitem>
	    	<para><acronym
	    	  role="Portable Operating System Interface">POSIX</acronym>
	    	  compatible name (e.g., <replaceable>joe</replaceable>).</para>
	  	  </listitem>
	  	  <listitem>
	    	<para><acronym
	    	  role="Portable Operating System Interface">POSIX</acronym>
	    	  numeric ID (e.g., <replaceable>789</replaceable>).</para>
	  	  </listitem>
	  	  <listitem>
	    	<para><acronym
	    	  role="System Identifier">SID</acronym>
	    	  name (e.g.,
	    	  <replaceable>joe.bloggs@example.com</replaceable>).</para>
	  	  </listitem>
	  	  <listitem>
	    	<para><acronym role="System Identifier">SID</acronym>
	    	  numeric ID (e.g.,
	    	  <replaceable>S-1-123-456-789</replaceable>).</para>
	  	  </listitem>
		</itemizedlist>

		<para>For example, to enforce a quota of 50&nbsp;GB for a user
		  named <replaceable>joe</replaceable>, use the
		  following:</para>

		<screen>&prompt.root; <userinput>zfs set userquota@joe=50G</userinput></screen>

		<para>To remove the quota or make sure that one is not
		  set, instead use:</para>

		<screen>&prompt.root; <userinput>zfs set userquota@joe=none</userinput></screen>

		<para>User quota properties are not displayed by
		  <command>zfs get all</command>. Non-<username>root</username>
		  users can only see their own quotas unless they have been
		  granted the <literal>userquota</literal> privilege.  Users
		  with this privilege are able to view and set everyone's
		  quota.</para>

		<para>The group quota limits the amount of space that a
		  specified user group can consume.  The general format is
		  <literal>groupquota@<replaceable>group</replaceable>=<replaceable>size</replaceable></literal>.</para>

		<para>To set the quota for the group
		  <replaceable>firstgroup</replaceable> to 50&nbsp;GB,
		  use:</para>

		<screen>&prompt.root; <userinput>zfs set groupquota@firstgroup=50G</userinput></screen>

		<para>To remove the quota for the group
		  <replaceable>firstgroup</replaceable>, or make sure that one
		  is not set, instead use:</para>

		<screen>&prompt.root; <userinput>zfs set groupquota@firstgroup=none</userinput></screen>

		<para>As with the user quota property,
		  non-<username>root</username> users can only see the quotas
		  associated with the user groups that they belong to, however
		  a <username>root</username> user or a user with the
		  <literal>groupquota</literal> privilege can view and set all
		  quotas for all groups.</para>

		<para>The <command>zfs userspace</command> subcommand displays
		  the amount of space consumed by each user on the specified
		  filesystem or snapshot, along with any specified quotas.
		  The <command>zfs groupspace</command> subcommand does the
		  same for groups.  For more information about supported
		  options, or only displaying specific options, see
		  &man.zfs.1;.</para>

		<para>To list the quota for
		  <filename>storage/home/bob</filename>, if you have the
		  correct privileges or are <username>root</username>,
		  use the following:</para>

		<screen>&prompt.root; <userinput>zfs get quota storage/home/bob</userinput></screen>
      </sect3>

      <sect3>
		<title>ZFS Reservations</title>

		<para>ZFS supports two types of space reservations.  This
		  section will explain the basics of each one, and include
		  some usage instructions.</para>

		<para>The <literal>reservation</literal> property makes it
		  possible to reserve a minimum amount of space guaranteed for a
		  dataset and its descendants.  This means that if a 10&nbsp;GB
		  reservation is set on <filename>storage/home/bob</filename>,
		  if disk space gets low, at least 10&nbsp;GB of space is
		  reserved for this dataset.  The
		  <literal>refreservation</literal> property sets or indicates
		  the minimum amount of space guaranteed to a dataset excluding
		  descendants, such as snapshots.  As an example, if a snapshot
		  was taken of <filename>storage/home/bob</filename>, enough
		  disk space would have to exist outside of the
		  <literal>refreservation</literal> amount for the operation to
		  succeed because descendants of the main data set are not
		  counted by the <literal>refreservation</literal> amount and
		  so do not encroach on the space set.</para>

		<para>Reservations of any sort are useful in many situations,
		  for example planning and testing the suitability of disk space
		  allocation in a new system, or ensuring that enough space is
		  available on file systems for system recovery procedures and
		  files.</para>

		<para>The general format of the <literal>reservation</literal>
		  property is
		  <literal>reservation=<replaceable>size</replaceable></literal>,
		  so to set a reservation of 10&nbsp;GB on
		  <filename>storage/home/bob</filename>the below command is
		  used:</para>

		<screen>&prompt.root; <userinput>zfs set reservation=10G storage/home/bob</userinput></screen>

		<para>To make sure that no reservation is set, or to remove a
		  reservation, instead use:</para>

		<screen>&prompt.root; <userinput>zfs set reservation=none storage/home/bob</userinput></screen>

		<para>The same principle can be applied to the
		  <literal>refreservation</literal> property for setting a
		  refreservation, with the general format
		  <literal>refreservation=<replaceable>size</replaceable></literal>.</para>

		<para>To check if any reservations or refreservations exist on
		  <filename>storage/home/bob</filename>, execute one of the
		  following commands:</para>

		<screen>&prompt.root; <userinput>zfs get reservation storage/home/bob</userinput>
&prompt.root; <userinput>zfs get refreservation storage/home/bob</userinput></screen>
      </sect3>
    </sect2>
  </sect1>

  <sect1 id="filesystems-linux">
    <title>&linux; Filesystems</title>

    <para>This section will describe some of the &linux; filesystems
      supported by &os;.</para>

    <sect2>
      <title>Ext2FS</title>

      <para>The &man.ext2fs.5; file system kernel implementation was
	written by Godmar Back, and the driver first appeared in
	&os; 2.2.  In &os; 8 and earlier, the code is licensed under
	the <acronym>GNU</acronym> Public License, however under &os; 9,
	the code has been rewritten and it is now licensed under the
	<acronym>BSD</acronym> license.</para>

      <para>The &man.ext2fs.5; driver will allow the &os; kernel
	to both read and write to <acronym>ext2</acronym> file systems.</para>

      <para>First, load the kernel loadable module:</para>

      <screen>&prompt.root; <userinput>kldload ext2fs</userinput></screen>

      <para>Then, to mount an &man.ext2fs.5; volume located on
	<filename>/dev/ad1s1</filename>:</para>

      <screen>&prompt.root; <userinput>mount -t ext2fs /dev/ad1s1 /mnt</userinput></screen>
    </sect2>
    <sect2>
      <title>XFS</title>

      <para>The X file system, <acronym>XFS</acronym>, was originally
	written by <acronym>SGI</acronym> for the
	<acronym>IRIX</acronym> operating system, and they ported it
	to &linux;.  The source code has been released under the
	<acronym>GNU</acronym> Public License.  See
	<ulink url="http://oss.sgi.com/projects/xfs">this page</ulink>
	for more details.  The &os; port was started by Russel
	Cattelan, &a.kan;, and &a.rodrigc;.</para>

      <para>To load <acronym>XFS</acronym> as a kernel-loadable
	module:</para>

      <screen>&prompt.root; <userinput>kldload xfs</userinput></screen>

      <para>The &man.xfs.5; driver lets the &os; kernel access
	XFS filesystems.  However, at present only read-only
	access is supported.  Writing to a volume is not
	possible.</para>

      <para>To mount a &man.xfs.5; volume located on
	<filename>/dev/ad1s1</filename>, do the following:</para>

      <screen>&prompt.root; <userinput>mount -t xfs /dev/as1s1 /mnt</userinput></screen>

      <para>Also useful to note is that the
	<filename role="package">sysutils/xfsprogs</filename> port
	contains the <command>mkfs.xfs</command> utility which enables
	creation of <acronym>XFS</acronym> filesystems, plus utilities
	for analysing and repairing them.</para>

      <para>The <literal>-p</literal> flag to
	<command>mkfs.xfs</command> can be used to create an
	&man.xfs.5; filesystem which is populated with files and other
	metadata.  This can be used to quickly create a read-only
	filesystem which can be tested on &os;.</para>
    </sect2>
    <sect2>
      <title>ReiserFS</title>

      <para>The Reiser file system, ReiserFS, was ported to
	&os; by &a.dumbbell;, and has been released under the
	<acronym>GNU</acronym> Public License.</para>

      <para>The ReiserFS driver will permit the &os; kernel to
	access ReiserFS file systems and read their contents, but not
	write to them, currently.</para>

      <para>First, the kernel-loadable module needs to be loaded:</para>

      <screen>&prompt.root; <userinput>kldload reiserfs</userinput></screen>

      <para>Then, to mount a ReiserFS volume located on
	<filename>/dev/ad1s1</filename>:</para>

      <screen>&prompt.root; <userinput>mount -t reiserfs /dev/ad1s1 /mnt</userinput></screen>
    </sect2>
  </sect1>

  <!--
      XXXTR: stub sections (added later, as needed, as desire,
      after I get opinions from -doc people):

      Still need to discuss native and foreign file systems.

  <sect1>
    <title>Device File System</title>
  </sect1>

  <sect1>
    <title>DOS and NTFS File Systems</title>
    <para>This is a good section for those who transfer files, using
      USB devices, from Windows to FreeBSD and vice-versa.  My camera,
      and many other cameras I have seen default to using FAT16.  There
      is (was?) a kde utility, I think called kamera, that could be used
      to access camera devices.  A section on this would be useful.</para>

    <para>XXXTR: Though!  The disks chapter, covers a bit of this and
      devfs under it's USB devices.  It leaves a lot to be desired though,
      see:
http://www.freebsd.org/doc/en_US.ISO8859-1/books/handbook/usb-disks.html
      It may be better to flesh out that section a bit more.  Add the
      word "camera" to it so that others can easily notice.</para>
  </sect1>

  <sect1>
    <title>Linux EXT File System</title>

    <para>Probably NOT as useful as the other two, but it requires
      knowledge of the existence of the tools.  Which are hidden in
      the ports collection.  Most Linux guys would probably only use
      Linux, BSD guys would be smarter and use NFS.</para>
  </sect1>

  <sect1>
    <title>HFS</title>

    <para>I think this is the file system used on Apple OSX.  There are
      tools in the ports collection, and with Apple being a big
      FreeBSD supporter and user of our technologies, surely there
      is enough cross over to cover this?</para>
  </sect1>
  -->

</chapter>
