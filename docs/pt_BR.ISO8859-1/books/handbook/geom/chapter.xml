<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
<!--
     The FreeBSD Documentation Project
     $FreeBSD$

-->

<chapter id="GEOM">
  <chapterinfo>
    <authorgroup>
      <author>
	<firstname>Tom</firstname>
	<surname>Rhodes</surname>
	<contrib>Uma Colaboração de </contrib>
      </author>
    </authorgroup>
  </chapterinfo>

  <title>GEOM: Framework Modular para Trasformação de Discos</title>

  <sect1 id="GEOM-synopsis">
    <title>Sinopse</title>

    <indexterm>
      <primary>GEOM</primary>
    </indexterm>
    <indexterm>
      <primary>GEOM Disk Framework</primary>
      <see>GEOM</see>
    </indexterm>

    <para>Este capítulo aborda o uso de discos com o framework GEOM no 
	&os;. Isso inclui a maioria das utilidades de controle para 
	utilização de <acronym role="Redundant Array of Inexpensive Disks">
	RAID</acronym>, que podem fazer uso das configurações desse 
	framework. Este capítulo não entrará em detalhes de como o 
	GEOM manipula ou controla I/O, como funciona seu sistema 
	subjacente ou código. Essas informações você pode obter na 
	página de manual &man.geom.4; e suas referências. Este capítulo, 
	também, não é um guia definitivo para configurações de 
	<acronym>RAID</acronym>. Apenas as configurações de 
	<acronym>RAID</acronym> suportadas pelo GEOM serão discutidas 
	aqui.</para>

    <para>Depois de ler este capítulo, você saberá:</para>

    <itemizedlist>
      <listitem>
	<para>Quais tipos de <acronym>RAID</acronym> são suportados 
	  e disponíveis através do uso do GEOM.</para>
      </listitem>

      <listitem>
	<para>Como utilizar os utilitários básicos para configurar, 
	  manter e manipular vários níveis de 
	  <acronym>RAID</acronym>.</para>
      </listitem>

      <listitem>
	<para>Como espelhar, dividir, encriptar e conectar 
	  dispositivos de disco remotamente com GEOM.</para>
      </listitem>

      <listitem>
	<para>Como solucionar problemas com discos interligados 
	  com uso do framework GEOM.</para>
      </listitem>
    </itemizedlist>

    <para>Antes de ler este capítulo, você deve:</para>

    <itemizedlist>
      <listitem>
	<para>Compreender como o &os; trata dispositivos de disco 
	  (<xref linkend="disks"/>).</para>
      </listitem>

      <listitem>
	<para>Saber como configurar e instalar um novo kernel 
	  (<xref linkend="kernelconfig"/>).</para>
      </listitem>
    </itemizedlist>
  </sect1>

  <sect1 id="GEOM-intro">
    <title>Introduzindo o GEOM</title>

    <para>O GEOM permite acessar e controlar classes &mdash; Master 
	Boot Records (MBR), labels tipo <acronym>BSD</acronym> e etc 
	&mdash; através do uso de chamadas ou arquivos especiais 
	presentes no diretório <filename class="directory">/dev</filename> 
	que venham a prover tais funcionalidades. Suportando vários 
	tipos de configuração de <acronym>RAID</acronym> por 
	software, o GEOM fornecerá acesso para utilitários usados pelo 
	sistema operacional de forma transparente.</para>
  </sect1>

  <sect1 id="GEOM-striping">
    <sect1info>
      <authorgroup>
	<author>
	  <firstname>Tom</firstname>
	  <surname>Rhodes</surname>
	  <contrib>Uma Contribuição de </contrib>
	</author>
	<author>
	  <firstname>Murray</firstname>
	  <surname>Stokely</surname>
	</author>
      </authorgroup>
    </sect1info>

    <title>RAID 0 - Divisão (<literal>Striping</literal>)</title>

    <indexterm>
      <primary>GEOM</primary>
    </indexterm>
    <indexterm>
      <primary>Striping</primary>
    </indexterm>

    <para>Divisão (<literal>Striping</literal>) é o método utilizado 
	para combinar diversos dispositivos de disco num volume único. 
	Em muitos casos isso é feito através do uso de controladoras 
	de hardware. O subsistema de discos do GEOM fornecem a 
	possibilidade de se usar <acronym>RAID</acronym> 0 
	(<literal>striping</literal>) por software.</para>

    <para>Num sistema com <acronym>RAID</acronym> 0, os dados são 
	divididos em blocos que, por sua vez, são escritos pelos 
	dispositivos que compoem o array do volume criado. Ao invés de 
	ter que esperar o sistema escrever 256k num único disco, um 
	sistema com <acronym>RAID</acronym> 0 pode, por exemplo, 
	escrever 64k em quatro diferentes discos simultaneamente 
	oferecendo uma performance superior. Esta performance pode ser 
	ainda mais incrementada com uso de múltiplas controladoras 
	de disco.</para>

    <para>Cada disco num <acronym>RAID</acronym> 0 
	(<literal>stripe</literal>) deve ser exatamente do mesmo 
	tamanho, visto que as operações e requisições de I/O são 
	intrelaçadas de forma a ler ou escrever dados nos discos 
	em paralelo.</para>

    <mediaobject>
      <imageobject>
	<imagedata fileref="geom/striping" align="center"/>
      </imageobject>

      <textobject>
	<phrase>Disk Striping Illustration</phrase>
      </textobject>
    </mediaobject>

    <procedure>
      <title>Criando RAID 0 com Discos ATA não Formatados</title>

      <step>
	<para>Carregue o módulo <filename>geom_stripe.ko</filename>:</para>

	<screen>&prompt.root; <userinput>kldload geom_stripe</userinput></screen>
      </step>

      <step>
	<para>Certifique-se de que existe um ponto de montagem hábil 
	  a receber o volume que será criado. Se este volume for 
	  receber alguma partição raíz, então use um outro ponto de 
	  montagem temporário (<filename 
	  class="directory">/mnt</filename>, neste exemplo):</para>

	<screen>&prompt.root; <userinput>mkdir /mnt</userinput></screen>
      </step>

      <step>
	<para>Descubra como os discos que você pretende usar foram 
	  identificados pelo &os; e crie a divisão 
	  (<literal>stripe</literal>). Para este exemplo foram 
	  utilizados dois discos <acronym>ATA</acronym> não 
	  particionados e identificados pelo sistema como 
	  <filename>/dev/ad2</filename> e 
	  <filename>/dev/ad3</filename>:</para>

	<screen>&prompt.root; <userinput>gstripe label -v st0 /dev/ad2 /dev/ad3</userinput>
Metadata value stored on /dev/ad2.
Metadata value stored on /dev/ad3.
Done.</screen>
      </step>

      <step>
	<para>Grave um particionamento (<literal>BSD Label</literal>) 
	  padrão neste novo volume e instale o código de 
	  bootstrap (inicialização) padrão:</para>

	<screen>&prompt.root; <userinput>bsdlabel -wB /dev/stripe/st0</userinput></screen>
      </step>

      <step>
	<para>Esse processo deve ter criado outros dois dispositivos 
	  no diretório <filename class="directory">/dev/stripe</filename> 
	  fazendo referência ao <devicename>st0</devicename> que foi 
	  criado anteriormente. Os novos dispositivos são 
	  <devicename>st0a</devicename> e 
	  <devicename>st0c</devicename>. Neste ponto um sistema de 
	  arquivos já pode ser criado em <devicename>st0a</devicename> 
	  com o utilitário <command>newfs</command>:</para>

	<screen>&prompt.root; <userinput>newfs -U /dev/stripe/st0a</userinput></screen>

	<para>Vários números irão aparecer na tela e, depois de 
	  alguns segundos, o processo estará terminado. Seu volume 
	  terá sido criado e estará pronto para uso.</para>
      </step>
    </procedure>

    <para>Para montar manualmente o novo volume criado:</para>

    <screen>&prompt.root; <userinput>mount /dev/stripe/st0a /mnt</userinput></screen>

    <para>Para montar o novo volume automaticamente durante o processo 
	de inicialização do &os; adicione uma entrada no arquivo 
	<filename>/etc/fstab</filename>. Neste exemplo criou-se o 
	diretório <filename class="directory">/stripe</filename> para 
	demonstrar esta configuração:</para>

    <screen>&prompt.root; <userinput>mkdir /stripe</userinput>
&prompt.root; <userinput>echo "/dev/stripe/st0a /stripe ufs rw 2 2" &gt;&gt; /etc/fstab</userinput></screen>

    <para>O módulo <filename>geom_stripe.ko</filename> também pode 
	ser carregado automaticamente durante o processo de 
	inicialização do sistema. Para isso, adicione a seguinte 
	entrada no arquivo <filename>/boot/loader.conf</filename>:</para>

    <screen>&prompt.root; <userinput>echo 'geom_stripe_load="YES"' &gt;&gt; /boot/loader.conf</userinput></screen>
  </sect1>

  <sect1 id="GEOM-mirror">
    <title>RAID 1 - Espelhamento (<literal>Mirroring</literal>)</title>

    <indexterm>
      <primary>GEOM</primary>
    </indexterm>
    <indexterm>
      <primary>Disk Mirroring</primary>
    </indexterm>

    <para>Espelhamento (<literal>Mirroring</literal>) é uma tecnologia 
	utilizada por diversas organizações e usuários domésticos para 
	garantir o <literal>backup</literal> de dados sem interrupção. 
	Quando um espelhamento existe, significa dizer que um disco 
	B é réplica de um disco A (ou, talvez, que discos C e D são 
	réplicas de discos A e B). Independentemente do tamanho do disco 
	ou partição, o aspecto importante aqui é que toda a informação 
	é replicada. Num outro momento esta informação pode ser mais 
	facilmente restaurada ou movida sem causar a interrupção 
	de serviços.</para>

    <para>Para começar, garanta que existam dois discos do mesmo 
	tamanho. Neste exercício, assuma que existem dois discos 
	<acronym>SCSI</acronym> (veja mais informações na página de 
	manual &man.da.4;).</para>

    <sect2>
      <title>Espelhando Discos</title>

      <para>Assumindo que o &os; foi instalado no disco primário da 
	máquina (detectado como <devicename>da0</devicename>), deve-se 
	dizer ao &man.gmirror.8; para gravar seus dados 
	preferencialmente neste disco primário (que será, também, o 
	disco principal para este exemplo).</para>

      <para>Antes de construir este espelho (<literal>mirror</literal>), 
	habilite a depuração adicional de erros e detecção de acesso 
	à dispositivos alterando a opção 
	<varname>kern.geom.debugflags</varname> com o comando 
	&man.sysctl.8;:</para>

      <screen>&prompt.root; <userinput>sysctl kern.geom.debugflags=17</userinput></screen>

      <para>Agora crie o espelho. Começe o procedimento armazenando 
	metadados no disco principal; para isso será criado o 
	dispositivo <filename class="devicefile">/dev/mirror/gm</filename> 
	com ajuda do seguinte comando:</para>

      <warning>
	<para>Criar um espelhamento fora do disco de inicialização 
	  pode resultar na perda de dados caso já existam dados gravados 
	  no último setor daquele disco. Este risco é bem menor quando 
	  você cria o espelhamento loco após uma instalação recém 
	  concluída do &os;. O seguinte procedimento também é 
	  incompatível com as configurações padrões utilizadas pelo 
	  &os; 9.<replaceable>X</replaceable>, que utiliza um novo 
	  esquema de particionamento tipo <acronym>GPT</acronym>. O 
	  GEOM iria sobrescrever os metadados utilizados pelo 
	  <acronym>GPT</acronym> e causaria, muito provavelmente, 
	  problemas que impossibilitariam a inicialização correta de 
	  todo o sistema e perda de dados.</para>
      </warning>

      <screen>&prompt.root; <userinput>gmirror label -vb round-robin gm0 /dev/da0</userinput></screen>

      <para>Logo após a execução do comando, o sistema deve 
	responder com algo parecido com:</para>

      <screen>Metadata value stored on /dev/da0.
Done.</screen>

      <para>Agora inicialize o GEOM. Isso também fará com que o 
	módulo <filename>geom_mirror.ko</filename> seja carregado:</para>

      <screen>&prompt.root; <userinput>gmirror load</userinput></screen>

      <note>
	<para>Quando a execução destes comandos tiver terminado com 
	  sucesso, um dispositivo nomeado de 
	  <devicename>gm0</devicename> será criado no diretório 
	  <filename class="directory">/dev/mirror</filename>.</para>
      </note>

      <para>Configure seu sistema para que o módulo 
	<filename>geom_mirror.ko</filename> seja carregado durante a 
	inicialização do sistema. Você pode fazer isso da seguinte 
	forma:</para>

      <screen>&prompt.root; <userinput>echo 'geom_mirror_load="YES"' &gt;&gt; /boot/loader.conf</userinput></screen>

      <para>Edite, então, as configurações no arquivo 
	<filename>/etc/fstab</filename> que façam mensão ao antigo 
	dispositivo (<devicename>da0</devicename>) e utilize o novo 
	dispositivo de espelhamento que foi criado 
	(<devicename>gm0</devicename>).</para>

      <note>
	<para>Se o &man.vi.1; for seu editor preferido, existe um 
	  jeito fácil de realizar estas modificações:</para>

	<screen>&prompt.root; <userinput>vi /etc/fstab</userinput></screen>

	<para>No &man.vi.1; você já poderá criar um backup do conteúdo 
	  do seu <filename>fstab</filename> digitando 
	  <userinput>:w /etc/fstab.bak</userinput>.  Então substitua 
	  todas as antigas entradas de <devicename>da0</devicename> 
	  por <devicename>gm0</devicename> digitando 
	  <userinput>:%s/da/mirror\/gm/g</userinput>.</para>
      </note>

      <para>Após as alterações no <filename>fstab</filename> o arquivo 
	pode ser semelhante ao exemplo abaixo. O fato dos discos 
	envolvidos serem do <acronym>SCSI</acronym> ou 
	<acronym>ATA</acronym> não mudará o fato de que o 
	espelhamento (<acronym>RAID</acronym> 1) feito receberá o 
	nome de <devicename>gm0</devicename>.</para>

      <programlisting># Device		Mountpoint	FStype	Options		Dump	Pass#
/dev/mirror/gm0s1b	none		swap	sw		0	0
/dev/mirror/gm0s1a	/		ufs	rw		1	1
/dev/mirror/gm0s1d	/usr		ufs	rw		0	0
/dev/mirror/gm0s1f	/home		ufs	rw		2	2
#/dev/mirror/gm0s2d	/store		ufs	rw		2	2
/dev/mirror/gm0s1e	/var		ufs	rw		2       2
/dev/acd0		/cdrom		cd9660	ro,noauto	0	0</programlisting>

      <para>Reinicie o sistema:</para>

      <screen>&prompt.root; <userinput>shutdown -r now</userinput></screen>

      <para>Durante o processo de inicialização do sistema, você 
	deverá notar que <devicename>gm0</devicename> será usado ao 
	invés de <devicename>da0</devicename>. Uma vez terminado o 
	processo de inicialização por completo, é possível de se 
	verificar esta alteração com ajuda do comando 
	<command>mount</command>:</para>

      <screen>&prompt.root; <userinput>mount</userinput>
Filesystem         1K-blocks    Used    Avail Capacity  Mounted on
/dev/mirror/gm0s1a   1012974  224604   707334    24%    /
devfs                      1       1        0   100%    /dev
/dev/mirror/gm0s1f  45970182   28596 42263972     0%    /home
/dev/mirror/gm0s1d   6090094 1348356  4254532    24%    /usr
/dev/mirror/gm0s1e   3045006 2241420   559986    80%    /var
devfs                      1       1        0   100%    /var/named/dev</screen>

      <para>A saída do comando parece boa, como já era de se esperar. 
	Finalmente, para dar início ao processo de sincronização 
	entre os discos espelhados, adicione o dispositivo que deverá 
	receber a replicação do disco principal. Neste caso o 
	dispositivo utilizado foi detectado como 
	<devicename>da1</devicename> e será adicionado ao 
	espelhamento com o seguinte comando:</para>

      <screen>&prompt.root; <userinput>gmirror insert gm0 /dev/da1</userinput></screen>

      <para>Enquanto a replicação de dados é realizada, você pode 
	verificar o status com o seguinte comando:</para>

      <screen>&prompt.root; <userinput>gmirror status</userinput></screen>

      <para>Uma vez que o processo de réplica for finalizado, a 
	saída do comando acima deverá ser semelhante a:</para>

      <screen>      Name    Status  Components
mirror/gm0  COMPLETE  da0
                      da1</screen>

      <para>Se existir alguma complicação, ou se o processo ainda 
	não tiver sido concluído, o status será apresentado como 
	<literal>DEGRADED</literal> ao invés de 
	<literal>COMPLETE</literal>.</para>
    </sect2>

    <sect2>
      <title>Solução de Problemas</title>

      <sect3>
	<title>O Sistema não Inicializa</title>

	<para>Se o sistema parar durante o processo de inicialização 
	  e exibir uma mensagem similar a esta:</para>

	<programlisting>ffs_mountroot: can't find rootvp
Root mount failed: 6
mountroot></programlisting>

	<para>Reinicie sua máquina precionando o botão de liga/desliga 
	  ou reset. No menu com opções de inicialização, selecione a 
	  opção 6. Esta opção irá lhe fornecer um 
	  <literal>prompt</literal> de comando do &man.loader.8;. 
	  Carregue, então, o módulo no kernel e tente iniciar 
	  o &os; normalmente:</para>

	<screen>OK? <userinput>load geom_mirror</userinput>
OK? <userinput>boot</userinput></screen>

	<para>Se este procedimento funcionar, isso indica que, por 
	  algum motivo, o módulo responsável pelo espelhamento feito 
	  através do GEOM não foi carregado automaticamente de forma 
	  correta. Verifique se as configurações no arquivo 
	  <filename>/boot/loader.conf</filename> estão corretas. 
	  Caso o problema continue, adicione a entrada</para>

	<programlisting>options	GEOM_MIRROR</programlisting>

	<para>no arquivo de configuração do kernel, recompile-o e 
	  instale-o. Isso deve remediar o problema.</para>
      </sect3>
    </sect2>

    <sect2>
      <title>Recuperando-se de Falhas em Discos</title>

      <para>A melhor parte sobre espelhamento de discos é que quando 
	um disco falha ele pode ser substituído, presumidamente, sem 
	que nenhuma informação tenha sido perdida</para>

      <para>Considerando o exemplo anterior com a configuração em 
	<acronym>RAID</acronym> 1 que foi feita, assuma que 
	<devicename>da1</devicename> é um disco que tenha falhado e 
	precisa ser trocado. Para realizar tal procedimento, 
	identifique qual disco físico corresponde a unidade 
	<devicename>da1</devicename> e desligue seu sistema. Neste 
	ponto o disco com falha deve ser trocado por um novo disco 
	e o sistema já pode ser religado. Depois do sistema ter 
	inicializado novamente, os seguintes comandos podem ser 
	usados para efetuar a troca do disco no espelhamento:</para>

      <screen>&prompt.root; <userinput>gmirror forget gm0</userinput></screen>

      <screen>&prompt.root; <userinput>gmirror insert gm0 /dev/da1</userinput></screen>

      <para>Use o comando <command>gmirror</command> <option>status</option>
	para monitorar o andamento do processo de réplica entre os 
	discos. É simples assim.</para>
    </sect2>
  </sect1>

  <sect1 id="GEOM-raid3">
    <sect1info>
      <authorgroup>
	<author>
	  <firstname>Mark</firstname>
	  <surname>Gladman</surname>
	  <contrib>Uma Contribuição de </contrib>
	</author>
	<author>
	  <firstname>Daniel</firstname>
	  <surname>Gerzo</surname>
	</author>
      </authorgroup>
      <authorgroup>
	<author>
	  <firstname>Tom</firstname>
	  <surname>Rhodes</surname>
	  <contrib>Baseado na Documentação de </contrib>
	</author>
	<author>
	  <firstname>Murray</firstname>
	  <surname>Stokely</surname>
	</author>
      </authorgroup>
    </sect1info>

    <title><acronym>RAID</acronym> 3 - Divisão (<literal>Striping</literal>) 
	a Nível de Byte com Disco de Paridade</title>

    <indexterm>
      <primary>GEOM</primary>
    </indexterm>
    <indexterm>
      <primary>RAID3</primary>
    </indexterm>

    <para>O <acronym>RAID</acronym> 3 é um método utilizado para 
      combinar diversos dispositivos de disco num único volume e 
      faz uso de um disco de paridade dedicado. Num sistema com este 
      tipo de <acronym>RAID</acronym>, os dados são divididos em num 
      número de bytes que são escritos em todos os discos que fazem 
      parte do array exceto por um dos discos, que funciona, 
      dedicadamente, como disco de paridade. Isso significa que a 
      leitura de 1024KB numa implementação em <acronym>RAID</acronym> 
      3 irá acessar os dados em todos os discos do array &mdash; a 
      performance pode ser melhorada através do uso de diversas 
      controladores de disco. <acronym>RAID</acronym> 3 provê 
      tolerância a falha para 1 dos discos do array enquanto provê 
      capacidade de armazenamento <quote>1 - 1/n</quote> vezes a 
      capacidade total de todos os discos que compõem o array, onde 
      <replaceable>n</replaceable> é o número de discos neste array. 
      Tal tipo de configuração é adequada, principalmente, para 
      cenários que necessitem armazenar arquivos grandes como, 
      por exemplo, arquivos de multimídia.</para>

    <para>Pelo menos 3 discos físicos são necessários para configurar 
      um <acronym>RAID</acronym> 3. Cada um dos discos deve ter o 
      mesmo tamanho, visto que as requisições de I/O são intercaladas 
      para leitura e escrita paralelamente entre múltiplos discos. 
      Também, dada a natureza do <acronym>RAID</acronym> 3, o número 
      de discos utilizados deve seguir a seguinte progressão: 
      3, 5, 9, 17 e etc 
      (2^<replaceable>n</replaceable> + 1).</para>

    <sect2>
      <title>Criando um Array Dedicado em <acronym>RAID</acronym> 3</title>

      <para>No &os;, o suporte a <acronym>RAID</acronym> 3 é 
	implementado pela a classe do &man.graid3.8;, pertencente 
	ao framework <acronym>GEOM</acronym>. A criação de um array 
	dedicado para este tipo de <acronym>RAID</acronym> no &os; 
	requer que você siga os passos a seguir.</para>

      <note>
	<para>Na teoria, é possível de se inicializar o &os; num 
	  sistema com <acronym>RAID</acronym> 3, mas este tipo de 
	  configuração é bastante incomum e não é aconselhável de 
	  se realizar.</para>
      </note>

      <procedure>
	<step>
	  <para>Primeiro, o módulo <filename>geom_raid3.ko</filename> 
	    deverá ser carregado com ajuda do seguinte comando:</para>

	  <screen>&prompt.root; <userinput>graid3 load</userinput></screen>

	  <para>Um outro jeito para se carregar este módulo 
	    manualmente é utilizando o comando 
	    <command>kldload</command> para este fim:</para>

	  <screen>&prompt.root; <userinput>kldload geom_raid3.ko</userinput></screen>
	</step>

	<step>
	  <para>Garanta que exista um ponto de montagem para receber 
	    o volume que será criado. Caso não exista, crie um 
	    diretório para tal finalidade:</para>

	  <screen>&prompt.root; <userinput>mkdir <replaceable>/multimedia</replaceable></userinput></screen>
	</step>

	<step>
	  <para>Determine quais dispositivos serão utilizados para a 
	    criação do array e crie um novo dispositivo agrupando-os 
	    em <acronym>RAID</acronym> 3. O último disco adicionado 
	    na listagem funcionará como disco de paridade. Neste exemplo 
	    foram utilizados 3 discos <acronym>ATA</acronym> ainda 
	    não particionados: 
	    <devicename><replaceable>ada1</replaceable></devicename>, 
	    <devicename><replaceable>ada2</replaceable></devicename> 
	    (armazenamento dos dados) e 
	    <devicename><replaceable>ada3</replaceable></devicename> 
	    (paridade do array).</para>

	  <screen>&prompt.root; <userinput>graid3 label -v gr0 /dev/ada1 /dev/ada2 /dev/ada3</userinput>
Metadata value stored on /dev/ada1.
Metadata value stored on /dev/ada2.
Metadata value stored on /dev/ada3.
Done.</screen>
	</step>

	<step>
	  <para>Particione o novo dispositivo criado 
	    (<devicename>gr0</devicename>) e utilize o sistema de 
	    arquivos UFS nele:</para>

	  <screen>&prompt.root; <userinput>gpart create -s GPT /dev/raid3/gr0</userinput>
&prompt.root; <userinput>gpart add -t freebsd-ufs /dev/raid3/gr0</userinput>
&prompt.root; <userinput>newfs -j /dev/raid3/gr0p1</userinput></screen>

	  <para>Vários números aparecerão na tela e, depois de um 
	    certo tempo, o processo será concluído. O volume terá 
	    sido criado e estará pronto para ser utilizado.</para>
	</step>

	<step>
	  <para>O último passo é montar o novo volume e usar seu 
	    sistema de arquivos:</para>

	  <screen>&prompt.root; <userinput>mount /dev/raid3/gr0p1 /multimedia</userinput></screen>

	  <para>Agora o volume em <acronym>RAID</acronym> 3 já está 
	    pronto para uso!</para>
	</step>
      </procedure>

      <para>Uma certa configuração adicional é necessária para 
	    garantir que o ambiente continue funcionando após o 
	    sistema ser reiniciado.</para>

      <procedure>
	<step>
	  <para>O módulo <filename>geom_raid3.ko</filename> deve ser 
	    carregado antes que o array seja montado. Para carregar 
	    este módulo automaticamente durante o processo de 
	    inicialização do &os;, adicione a seguinte entrada no 
	    arquivo <filename>/boot/loader.conf</filename> file:</para>

	  <programlisting>geom_raid3_load="YES"</programlisting>
	</step>

	<step>
	  <para>A seguinte entrada deve ser adicionada ao conteúdo 
	    do arquivo <filename>/etc/fstab</filename> para que o 
	    sistema de arquivos do array (volume) seja montado 
	    automaticamente durante o processo de inicialização do 
	    sistema:</para>

	  <programlisting>/dev/raid3/gr0p1	/multimedia	ufs	rw	2	2</programlisting>
	</step>
      </procedure>
    </sect2>
  </sect1>

  <sect1 id="geom-ggate">
    <title>GEOM e Dispositivos de Rede</title>

    <para>O GEOM suporta o uso de dispositivos remotos (unidades de 
      CD-ROM, discos, arquivos e etc) através de utilitários que lhe 
      fornecem tal função. É similar ao que pode ser feito com 
      <acronym>NFS</acronym>.</para>

    <para>Para começar, um arquivo que exportará os volumes precisa 
      ser criado. Este arquivo dirá quem têm permissão para acessar 
      determinado volume e quais serão essas permissões. Por 
      exemplo, para permitir acesso à partição 4 em seu primeiro 
      disco <acronym>SCSI</acronym> através da rede você teria que 
      editar o arquivo <filename>/etc/gg.exports</filename> para que 
      ele seja semelhante a:</para>

    <programlisting>192.168.1.0/24 RW /dev/da0s4d</programlisting>

    <para>Considerando que sua rede é endereçada com o bloco 
      192.168.1.0/24, este exemplo permite que todas as estações em sua 
      rede possam ter acesso a partição 
      <devicename>da0s4d</devicename> com permissões de leitura 
      e escrita.</para>

    <para>Para exportar corretamente este dispositivo, garanta que 
      ele esteja montado e que o daemon do servidor &man.ggated.8; 
      esteja em execução. Para iniciar o &man.ggated.8;, utilize o 
      seguinte comando:</para>

    <screen>&prompt.root; <userinput>ggated</userinput></screen>

    <para>Agora, para montar o dispositivo exportado numa estação 
      cliente, faça uso dos comandos <command>ggatec</command> e 
      <command>mount</command>:</para>

    <screen>&prompt.root; <userinput>ggatec create -o rw 192.168.1.1 /dev/da0s4d</userinput>
ggate0
&prompt.root; <userinput>mount /dev/ggate0 /mnt</userinput></screen>

    <para>Deste ponto em diante, o dispositivo remoto (no servidor 
      192.168.1.1) já pode ser acessado através do diretório 
      <filename class="directory">/mnt</filename> na estação cliente.</para>

    <note>
      <para>Atente para o fato de que este procedimento pode falhar 
	caso o dispositivo já tenha sido montado por uma outra 
	estação na rede (ou até mesmo pelo próprio servidor).</para>
    </note>

    <para>Quando não for mais necessário fazer uso do dispositivo 
	montado remotamente ele pode ser desmontado com segurança da 
	mesma forma que quaisquer outros discos locais, com auxílio 
	do comando &man.umount.8;.</para>
  </sect1>

  <sect1 id="geom-glabel">
    <title>Labeling Disk Devices</title>

    <indexterm>
      <primary>GEOM</primary>
    </indexterm>
    <indexterm>
      <primary>Disk Labels</primary>
    </indexterm>

    <para>During system initialization, the &os; kernel will create
      device nodes as devices are found.  This method of probing for
      devices raises some issues, for instance what if a new disk
      device is added via <acronym>USB</acronym>?  It is very likely
      that a flash device may be handed the device name of
      <devicename>da0</devicename> and the original
      <devicename>da0</devicename> shifted to
      <devicename>da1</devicename>.  This will cause issues mounting
      file systems if they are listed in
      <filename>/etc/fstab</filename>, effectively, this may also
      prevent the system from booting.</para>

    <para>One solution to this issue is to chain the
      <acronym>SCSI</acronym> devices in order so a new device added
      to the <acronym>SCSI</acronym> card will be issued unused device
      numbers.  But what about <acronym>USB</acronym> devices which
      may replace the primary <acronym>SCSI</acronym> disk?  This
      happens because <acronym>USB</acronym> devices are usually
      probed before the <acronym>SCSI</acronym> card.  One solution is
      to only insert these devices after the system has been booted.
      Another method could be to use only a single
      <acronym>ATA</acronym> drive and never list the
      <acronym>SCSI</acronym> devices in
      <filename>/etc/fstab</filename>.</para>

    <para>A better solution is available.  By using the
      <command>glabel</command> utility, an administrator or user may
      label their disk devices and use these labels in
      <filename>/etc/fstab</filename>.  Because
      <command>glabel</command> stores the label in the last sector of
      a given provider, the label will remain persistent across
      reboots.  By using this label as a device, the file system may
      always be mounted regardless of what device node it is accessed
      through.</para>

    <note>
      <para>This goes without saying that a label be permanent.  The
	<command>glabel</command> utility may be used to create both a
	transient and permanent label.  Only the permanent label will
	remain consistent across reboots.  See the &man.glabel.8;
	manual page for more information on the differences between
	labels.</para>
    </note>

    <sect2>
      <title>Label Types and Examples</title>

      <para>There are two types of labels, a generic label and a
	file system label.  Labels can be permanent or temporary.
	Permanent labels can be created with the &man.tunefs.8;
	or &man.newfs.8; commands.  They will then be created
	in a sub-directory of
	<filename class="directory">/dev</filename>, which will be
	named according to their file system type.  For example,
	<acronym>UFS</acronym>2 file system labels will be created in
	the <filename class="directory">/dev/ufs</filename> directory.
	Permanent labels can also be created with the <command>glabel
	label</command> command.  These are not file system specific,
	and will be created in the
	<filename class="directory">/dev/label</filename>
	directory.</para>

      <para>A temporary label will go away with the next reboot.
	These labels will be created in the
	<filename class="directory">/dev/label</filename> directory
	and are perfect for experimentation.  A temporary label can be
	created using the <command>glabel create</command> command.
	For more information, please read the manual page of
	&man.glabel.8;.</para>

<!-- XXXTR: How do you create a file system label without running newfs
	    or when there is no newfs (e.g.: cd9660)? -->

      <para>To create a permanent label for a
	<acronym>UFS</acronym>2 file system without destroying any
	data, issue the following command:</para>

      <screen>&prompt.root; <userinput>tunefs -L <replaceable>home</replaceable> <replaceable>/dev/da3</replaceable></userinput></screen>

      <warning>
	<para>If the file system is full, this may cause data
	  corruption; however, if the file system is full then the
	  main goal should be removing stale files and not adding
	  labels.</para>
      </warning>

      <para>A label should now exist in
	<filename class="directory">/dev/ufs</filename> which may be
	added to <filename>/etc/fstab</filename>:</para>

      <programlisting>/dev/ufs/home		/home            ufs     rw              2      2</programlisting>

      <note>
	<para>The file system must not be mounted while attempting
	  to run <command>tunefs</command>.</para>
      </note>

      <para>Now the file system may be mounted like normal:</para>

      <screen>&prompt.root; <userinput>mount /home</userinput></screen>

      <para>From this point on, so long as the
	<filename>geom_label.ko</filename> kernel module is loaded at
	boot with <filename>/boot/loader.conf</filename> or the
	<literal>GEOM_LABEL</literal> kernel option is present,
	the device node may change without any ill effect on the
	system.</para>

      <para>File systems may also be created with a default label
	by using the <option>-L</option> flag with
	<command>newfs</command>.  See the &man.newfs.8; manual page
	for more information.</para>

      <para>The following command can be used to destroy the
	label:</para>

      <screen>&prompt.root; <userinput>glabel destroy home</userinput></screen>

      <para>The following example shows how to label the partitions of
	a boot disk.</para>

      <example>
	<title>Labeling Partitions on the Boot Disk</title>

	<para>By permanently labeling the partitions on the boot disk,
	  the system should be able to continue to boot normally, even
	  if the disk is moved to another controller or transferred to
	  a different system.  For this example, it is assumed that a
	  single <acronym>ATA</acronym> disk is used, which is
	  currently recognized by the system as
	  <devicename>ad0</devicename>.  It is also assumed that the
	  standard &os; partition scheme is used, with
	  <filename class="directory">/</filename>,
	  <filename class="directory">/var</filename>,
	  <filename class="directory">/usr</filename> and
	  <filename class="directory">/tmp</filename> file systems, as
	  well as a swap partition.</para>

	<para>Reboot the system, and at the &man.loader.8; prompt,
	  press <keycap>4</keycap> to boot into single user mode.
	  Then enter the following commands:</para>

	<screen>&prompt.root; <userinput>glabel label rootfs /dev/ad0s1a</userinput>
GEOM_LABEL: Label for provider /dev/ad0s1a is label/rootfs
&prompt.root; <userinput>glabel label var /dev/ad0s1d</userinput>
GEOM_LABEL: Label for provider /dev/ad0s1d is label/var
&prompt.root; <userinput>glabel label usr /dev/ad0s1f</userinput>
GEOM_LABEL: Label for provider /dev/ad0s1f is label/usr
&prompt.root; <userinput>glabel label tmp /dev/ad0s1e</userinput>
GEOM_LABEL: Label for provider /dev/ad0s1e is label/tmp
&prompt.root; <userinput>glabel label swap /dev/ad0s1b</userinput>
GEOM_LABEL: Label for provider /dev/ad0s1b is label/swap
&prompt.root; <userinput>exit</userinput></screen>

	<para>The system will continue with multi-user boot.  After
	  the boot completes, edit <filename>/etc/fstab</filename> and
	  replace the conventional device names, with their respective
	  labels.  The final <filename>/etc/fstab</filename> file will
	  look like the following:</para>

	<programlisting># Device                Mountpoint      FStype  Options         Dump    Pass#
/dev/label/swap         none            swap    sw              0       0
/dev/label/rootfs       /               ufs     rw              1       1
/dev/label/tmp          /tmp            ufs     rw              2       2
/dev/label/usr          /usr            ufs     rw              2       2
/dev/label/var          /var            ufs     rw              2       2</programlisting>

	<para>The system can now be rebooted.  If everything went
	  well, it will come up normally and <command>mount</command>
	  will show:</para>

	<screen>&prompt.root; <userinput>mount</userinput>
/dev/label/rootfs on / (ufs, local)
devfs on /dev (devfs, local)
/dev/label/tmp on /tmp (ufs, local, soft-updates)
/dev/label/usr on /usr (ufs, local, soft-updates)
/dev/label/var on /var (ufs, local, soft-updates)</screen>
      </example>

      <para>Starting with &os;&nbsp;7.2, the &man.glabel.8; class
	supports a new label type for <acronym>UFS</acronym> file
	systems, based on the unique file system id,
	<literal>ufsid</literal>.  These labels may be found in the
	<filename class="directory">/dev/ufsid</filename> directory
	and are created automatically during system startup.  It is
	possible to use <literal>ufsid</literal> labels to mount
	partitions using the <filename>/etc/fstab</filename> facility.
	Use the <command>glabel status</command> command to receive a
	list of file systems and their corresponding
	<literal>ufsid</literal> labels:</para>

      <screen>&prompt.user; <userinput>glabel status</userinput>
                  Name  Status  Components
ufsid/486b6fc38d330916     N/A  ad4s1d
ufsid/486b6fc16926168e     N/A  ad4s1f</screen>

      <para>In the above example <devicename>ad4s1d</devicename>
	represents the <filename class="directory">/var</filename>
	file system, while <devicename>ad4s1f</devicename> represents
	the <filename class="directory">/usr</filename> file system.
	Using the <literal>ufsid</literal> values shown, these
	partitions may now be mounted with the following entries in
	<filename>/etc/fstab</filename>:</para>

      <programlisting>/dev/ufsid/486b6fc38d330916        /var        ufs        rw        2      2
/dev/ufsid/486b6fc16926168e        /usr        ufs        rw        2      2</programlisting>

      <para>Any partitions with <literal>ufsid</literal> labels can be
	mounted in this way, eliminating the need to create permanent
	labels for them manually, while still enjoying the benefits of
	device-name independent mounting.</para>
    </sect2>
  </sect1>

  <sect1 id="geom-gjournal">
    <title>UFS Journaling Through GEOM</title>

    <indexterm>
      <primary>GEOM</primary>
    </indexterm>
    <indexterm>
      <primary>Journaling</primary>
    </indexterm>

    <para>With the release of &os; 7.0, the long awaited feature
      of journals has been implemented.  The implementation itself is
      provided through the <acronym>GEOM</acronym> subsystem and is
      easily configured via the &man.gjournal.8; utility.</para>

    <para>What is journaling?  Journaling capability stores a log of
      file system transactions, i.e.: changes that make up a complete
      disk write operation, before meta-data and file writes are
      committed to the disk proper.  This transaction log can later
      be replayed to redo file system transactions, preventing file
      system inconsistencies.</para>

    <para>This method is yet another mechanism to protect against data
      loss and inconsistencies of the file system.  Unlike Soft
      Updates which tracks and enforces meta-data updates and
      Snapshots which is an image of the file system, an actual log is
      stored in disk space specifically reserved for this task, and in
      some cases may be stored on another disk entirely.</para>

    <para>Unlike other file system journaling implementations, the
      <command>gjournal</command> method is block based and not
      implemented as part of the file system - only as a
      <acronym>GEOM</acronym> extension.</para>

    <para>To enable support for <command>gjournal</command>, the
      &os; kernel must have the following option - which is the
      default on &os; 7.0 and later systems:</para>

    <programlisting>options	UFS_GJOURNAL</programlisting>

    <para>If journaled volumes need to be mounted during startup, the
      <filename>geom_journal.ko</filename> kernel module will also
      have to be loaded, by adding the following line in
      <filename>/boot/loader.conf</filename>:</para>

    <programlisting>geom_journal_load="YES"</programlisting>

    <para>Alternatively, this function can also be built into a custom
      kernel, by adding the following line in the kernel configuration
      file:</para>

    <programlisting>options	GEOM_JOURNAL</programlisting>

    <para>Creating a journal on a free file system may now be done
      using the following steps, considering that the
      <devicename>da4</devicename> is a new <acronym>SCSI</acronym>
      disk:</para>

    <screen>&prompt.root; <userinput>gjournal load</userinput>
&prompt.root; <userinput>gjournal label /dev/da4</userinput></screen>

    <para>At this point, there should be a
      <devicename>/dev/da4</devicename> device node and a
      <devicename>/dev/da4.journal</devicename> device node.
      A file system may now be created on this device:</para>

    <screen>&prompt.root; <userinput>newfs -O 2 -J /dev/da4.journal</userinput></screen>

    <para>The previously issued command will create a
      <acronym>UFS</acronym>2 file system on the journaled
      device.</para>

    <para>Effectively <command>mount</command> the device at the
      desired point with:</para>

    <screen>&prompt.root; <userinput>mount /dev/da4.journal <replaceable>/mnt</replaceable></userinput></screen>

    <note>
      <para>In the case of several slices, a journal will be created
	for each individual slice.  For instance, if
	<devicename>ad4s1</devicename> and
	<devicename>ad4s2</devicename> are both slices, then
	<command>gjournal</command> will create
	<devicename>ad4s1.journal</devicename> and
	<devicename>ad4s2.journal</devicename>.</para>
    </note>

    <para>For better performance, keeping the journal on another disk
      may be desired.  For these cases, the journal provider or
      storage device should be listed after the device to enable
      journaling on.  Journaling may also be enabled on current file
      systems by using <command>tunefs</command>; however, always make
      a backup before attempting to alter a file system.  In most
      cases, the <command>gjournal</command> will fail if it is unable
      to create the actual journal but this does not protect against
      data loss incurred as a result of misusing
      <command>tunefs</command>.</para>

    <para>It is also possible to journal the boot disk of a &os;
      system.  Please refer to the article <ulink
	url="&url.articles.gjournal-desktop;">Implementing UFS
	Journaling on a Desktop PC</ulink> for detailed instructions
      on this task.</para>
  </sect1>
</chapter>
